# -*- coding: utf-8 -*-
"""Classificador_Classes_Proc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-vmS1_QqUazbxaKUOOUBFGoCuVfiWUsX
"""

!pip install datasets

import pandas as pd
import torch
from transformers import LongformerTokenizer, LongformerForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from datasets import Dataset
from transformers import TrainerCallback

# Carregar o banco de dados SQLite3
import sqlite3
import json

# Verificar se a GPU está disponível
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Treinamento será realizado em: {device}")

conn = sqlite3.connect("documentos_tratados.db")
query = "select classe_processual classe, tratado_ocr_text_unida texto from base"
df = pd.read_sql_query(query, conn)
conn.close()

# Codificar as classes
label_encoder = LabelEncoder()
df['classe_encoded'] = label_encoder.fit_transform(df['classe'])

# Dividir os dados em treino e validação
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df['texto'].tolist(),
    df['classe_encoded'].tolist(),
    test_size=0.2,
    random_state=42
)

# Carregar o tokenizer Longformer
tokenizer = LongformerTokenizer.from_pretrained("allenai/longformer-base-4096")

# Tokenizar os textos
def tokenize_function(examples):
    return tokenizer(examples["text"], truncation=True, padding=True, max_length=4096)

# Preparar os datasets
train_data = Dataset.from_dict({"text": train_texts, "label": train_labels})
val_data = Dataset.from_dict({"text": val_texts, "label": val_labels})

train_data = train_data.map(tokenize_function, batched=True)
val_data = val_data.map(tokenize_function, batched=True)

train_data = train_data.rename_column("label", "labels")
val_data = val_data.rename_column("label", "labels")

train_data.set_format(type="torch", columns=["input_ids", "attention_mask", "labels"])
val_data.set_format(type="torch", columns=["input_ids", "attention_mask", "labels"])

# Carregar o modelo Longformer
model = LongformerForSequenceClassification.from_pretrained("allenai/longformer-base-4096", num_labels=len(label_encoder.classes_))

model.to(device)  # Transferir o modelo para a GPU (ou CPU, caso GPU não esteja disponível)

# Definir os parâmetros de treinamento
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",  # Avaliação após cada época
    logging_dir="./logs",
    logging_steps=10,
    per_device_train_batch_size=2,  # Use batch size pequeno devido ao alto custo computacional
    per_device_eval_batch_size=2,
    num_train_epochs=5,
    weight_decay=0.01,
    learning_rate=1e-5,
    save_total_limit=2,
    save_strategy="epoch",  # Salvar o modelo após cada época
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    report_to="none",  # Evita relatórios automáticos para serviços como TensorBoard
    lr_scheduler_type="linear",  # Usar scheduler linear para diminuir a taxa de aprendizado progressivamente
    warmup_steps=500,  # Número de passos para aquecer a taxa de aprendizado
    gradient_accumulation_steps=2,  # Acumular gradientes para simular um maior batch size
    fp16=True,  # Usar precisão de 16 bits para acelerar o treinamento, se suportado pela GPU
)

class SaveMetricsCallback(TrainerCallback):
    def __init__(self, file_name="evaluation_metrics.json"):
        self.file_name = file_name
        self.metrics = []

    def on_evaluate(self, args, state, control, metrics=None, **kwargs):
        if metrics is not None:
            self.metrics.append(metrics)
            with open(self.file_name, "w") as f:
                json.dump(self.metrics, f, indent=4)

    # Adicionar outros métodos necessários, como on_train_end
    def on_train_end(self, args, state, control, **kwargs):
        print("Treinamento finalizado!")
        # Você pode adicionar outro tipo de processamento se necessário

# Inicializar o callback
metrics_callback = SaveMetricsCallback()

# Definir o Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_data,
    eval_dataset=val_data,
    tokenizer=tokenizer,
    callbacks=[metrics_callback]
)

# Treinar o modelo
trainer.train()

# Salvar o modelo
model.save_pretrained("./longformer-classificador")
tokenizer.save_pretrained("./longformer-classificador")

# Exportar métricas finais em CSV (opcional)
pd.DataFrame(metrics_callback.metrics).to_csv("evaluation_metrics.csv", index=False)

import shutil

# Caminho da pasta a ser compactada
folder_path = "./longformer-classificador"

# Nome do arquivo ZIP de saída
zip_path = "./longformer-classificador.zip"

# Compactar a pasta
shutil.make_archive(zip_path.replace(".zip", ""), 'zip', folder_path)

import numpy as np
from sklearn.metrics import confusion_matrix
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Gerar previsões para o conjunto de validação
predictions, labels, _ = trainer.predict(val_data)

# As previsões retornadas são logits, então usamos argmax para obter as classes
predicted_labels = np.argmax(predictions, axis=1)

# Salvar as previsões e rótulos reais em um CSV (opcional)
df = pd.DataFrame({"real_labels": labels, "predictions": predicted_labels})
df.to_csv("predictions_and_labels.csv", index=False)

# Gerar a matriz de confusão
cm = confusion_matrix(df["real_labels"], df["predictions"])

# Plotar a matriz de confusão usando seaborn
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=df["real_labels"].unique(), yticklabels=df["real_labels"].unique())
plt.xlabel("Predições")
plt.ylabel("Rótulos reais")
plt.title("Matriz de Confusão")
plt.show()

import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Carregar os dados do CSV
data = pd.read_csv("predictions_and_labels.csv")

# Obter os rótulos reais e previstos
true_labels = data["real_labels"]
predicted_labels = data["predictions"]

# Calcular a matriz de confusão
conf_matrix = confusion_matrix(true_labels, predicted_labels)

# Calcular métricas detalhadas
report = classification_report(true_labels, predicted_labels, zero_division=0)

# Calcular acurácia
accuracy = accuracy_score(true_labels, predicted_labels)

# Exibir resultados
print("Matriz de Confusão:")
print(conf_matrix)
print("\nRelatório de Classificação:")
print(report)
print(f"\nAcurácia: {accuracy:.2f}")

train_labels